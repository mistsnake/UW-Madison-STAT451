{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8163daf4",
   "metadata": {},
   "source": [
    "### HW04: Practice with feature engineering, splitting data, and fitting and regularizing linear models\n",
    "\n",
    "Anais Corona Perez (NetID: coronaperez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdedd9b",
   "metadata": {},
   "source": [
    "### Hello Students:\n",
    "\n",
    "- Start by downloading HW04.ipynb from this folder. Then develop it into your solution.\n",
    "- Write code where you see \"... your code here ...\" below.\n",
    "  (You are welcome to use more than one cell.)\n",
    "- If you have questions, please ask them in class, office hours, or piazza. Our TA\n",
    "  and I are very happy to help with the programming (provided you start early\n",
    "  enough, and provided we are not helping so much that we undermine your learning).\n",
    "- When you are done, run these Notebook commands:\n",
    "  - Shift-L (once, so that line numbers are visible)\n",
    "  - Kernel > Restart and Run All (run all cells from scratch)\n",
    "  - Esc S (save)\n",
    "  - File > Download as > HTML\n",
    "- Turn in:\n",
    "  - HW04.ipynb to Canvas's HW04.ipynb assignment\n",
    "  - HW04.html to Canvas's HW04.html assignment\n",
    "  - As a check, download your files from Canvas to a new 'junk' folder. Try 'Kernel > Restart\n",
    "  and Run All' on the '.ipynb' file to make sure it works. Glance through the '.html' file.\n",
    "- Turn in partial solutions to Canvas before the deadline. e.g. Turn in part 1,\n",
    "  then parts 1 and 2, then your whole solution. That way we can award partial credit\n",
    "  even if you miss the deadline. We will grade your last submission before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a87448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90946b9",
   "metadata": {},
   "source": [
    "## 1. Feature engineering (one-hot encoding and data imputation)\n",
    "\n",
    "(Note: This paragraph is not instructions but rather is to communicate context for this exercise. We use the same Titanic data we used in HW02:\n",
    "- There we used `df.dropna()` to drop any observations with missing values; here we use data imputation instead.\n",
    "- There we manually did one-hot encoding of the categorical `Sex` column by making a `Female` column; here we do the same one-hot encoding with the help of pandas's `df.join(pd.get_dummies())`.\n",
    "- There we used a decision tree; here we use $k$-NN.\n",
    "\n",
    "We evaluate how these strategies can improve model performance by allowing us to use columns with categorical or missing data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa128a8c",
   "metadata": {},
   "source": [
    "### 1a. Read the data from [http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv](http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv).\n",
    "- Retain only these columns: Survived, Pclass, Sex, Age, SibSp, Parch.\n",
    "- Display the first 7 rows.\n",
    "\n",
    "These data are described at [https://www.kaggle.com/competitions/titanic/data](https://www.kaggle.com/competitions/titanic/data) (click on the small down-arrow to see the \"Data Dictionary\"), which is where they are from.\n",
    "- Read that \"Data Dictionary\" paragraph (with your eyes, not python) so you understand what each column represents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700852b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
       "0         0       3    male  22.0      1      0\n",
       "1         1       1  female  38.0      1      0\n",
       "2         1       3  female  26.0      0      0\n",
       "3         1       1  female  35.0      1      0\n",
       "4         0       3    male  35.0      0      0\n",
       "5         0       3    male   NaN      0      0\n",
       "6         0       1    male  54.0      0      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv')[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fda2ee",
   "metadata": {},
   "source": [
    "### 1b. Try to train a $k$NN model to predict $y=$ 'Survived' from $X=$ these features: 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch'.\n",
    "- Use $k = 3$ and the (default) euclidean metric.\n",
    "- Notice at the bottom of the error message that it fails with the error \"ValueError: could not convert string to float: 'male'\".\n",
    "- Comment out your .fit() line so the cell can run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf87ea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')\n",
    "#knn.fit(df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']], df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eea90e",
   "metadata": {},
   "source": [
    "### 1c. Try to train again, this time without the 'Sex' feature.\n",
    "- Notice that it fails because \"Input contains NaN\".\n",
    "- Comment out your .fit() line so the cell can run without error.\n",
    "- Run `X.isna().any()` (where X is the name of your DataFrame of features) to see that\n",
    "  the 'Age' feature has missing values. (You can see the first missing value in\n",
    "  the sixth row that you displayed above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4032cc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    False\n",
       "Age        True\n",
       "SibSp     False\n",
       "Parch     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "#knn.fit(df[['Pclass', 'Age', 'SibSp', 'Parch']], df.Survived)\n",
    "df[['Pclass', 'Age', 'SibSp', 'Parch']].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b103b9",
   "metadata": {},
   "source": [
    "### 1d. Train without the 'Sex' and 'Age' features.\n",
    "- Report accuracy on the training data with a line of the form\n",
    "  `Accuracy on training data is  0.500` (0.500 may not be correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e626bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is: 0.633\n"
     ]
    }
   ],
   "source": [
    "knn.fit(df[['Pclass', 'SibSp', 'Parch']], df.Survived)\n",
    "print(f'Accuracy on training data is:', round(knn.score(df[['Pclass', 'SibSp', 'Parch']], df.Survived), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617602",
   "metadata": {},
   "source": [
    "### 1e.  Use one-hot encoding\n",
    "to include a binary 'male'  feature made from the 'Sex' feature. (Or include a binary 'female'\n",
    "feature, according to your preference. Using both is unnecessary since either is the logical\n",
    "negation of the other.) That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male'.\n",
    "- Use pandas's df.join(pd.get_dummies())`.\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d04e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is: 0.744\n"
     ]
    }
   ],
   "source": [
    "df = df.join(pd.get_dummies(df['Sex']))\n",
    "knn.fit(df[['Pclass', 'SibSp', 'Parch', 'male']], df.Survived)\n",
    "print(f'Accuracy on training data is:', round(knn.score(df[['Pclass', 'SibSp', 'Parch', 'male']], df.Survived), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210618af",
   "metadata": {},
   "source": [
    "### 1f. Use data imputation\n",
    "to include an 'age' feature made from 'Age' but replacing each missing value with the median\n",
    "of the non-missing ages. That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male',\n",
    "'age'.\n",
    "\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0753fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is: 0.861\n"
     ]
    }
   ],
   "source": [
    "# Data imputation and replacement\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy = 'median', fill_value = None).fit_transform(df[['Age']])\n",
    "df['Age'] = imp\n",
    "\n",
    "#Train\n",
    "knn.fit(df[['Pclass', 'Age', 'SibSp', 'Parch', 'male']], df.Survived)\n",
    "print(f'Accuracy on training data is:', round(knn.score(df[['Pclass','Age', 'SibSp','Parch', 'male']], df.Survived), 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050084a",
   "metadata": {},
   "source": [
    "## 2. Explore model fit, overfit, and regularization in the context of multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fc1b2",
   "metadata": {},
   "source": [
    "### 2a. Prepare the data:\n",
    "- Read [http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv](http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv) into a DataFrame.\n",
    "- Set a variable `X` to the subset consisting of all columns except `mpg`.\n",
    "- Set a variable `y` to the `mpg` column.\n",
    "- Use `train_test_split()` to split `X` and `y` into `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "  - Reserve half the data for training and half for testing.\n",
    "  - Use `random_state=0` to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf49fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv')\n",
    "X = df.loc[:,df.columns != 'mpg'].drop(['Unnamed: 0'], axis = 1)\n",
    "y = df.mpg\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b3e11",
   "metadata": {},
   "source": [
    "### 2b. Train three models on the training data and evaluate each on the test data:\n",
    "- `LinearRegression()`\n",
    "- `Lasso()`\n",
    "- `Ridge()`\n",
    "\n",
    "The evaluation consists in displaying MSE$_\\text{train}, $ MSE$_\\text{test}$, and the coefficients $\\mathbf{w}$ for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb40699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Linear model: \n",
      " MSE train: 0.386 \n",
      " MSE test: 30.2 \n",
      " Intercept: -70.3 \n",
      " Coefficients: [ 1.08241627  0.02500827  0.02593759  3.12997296 -7.34326296  3.93233873\n",
      " -4.08551838 -1.2164054   5.98718293 -0.77097967]\n",
      "\n",
      "Evaluation of Lasso model: \n",
      " MSE train: 5.69 \n",
      " MSE test: 13.0 \n",
      " Intercept: 33.8 \n",
      " Coefficients: [-0.         -0.03718773 -0.01681757  0.         -0.          0.\n",
      "  0.          0.          0.         -0.84712891]\n",
      "\n",
      "Evaluation of Ridge model: \n",
      " MSE train: 1.99 \n",
      " MSE test: 11.2 \n",
      " Intercept: 7.25 \n",
      " Coefficients: [-0.01392446 -0.00744628  0.00400324  0.79271685 -3.21854592  1.09825372\n",
      " -0.48236992  0.47079795  1.49546846 -1.04547895]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on training data:\n",
    "linear = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "lasso = linear_model.Lasso().fit(X_train, y_train)\n",
    "ridge = linear_model.Ridge().fit(X_train, y_train)\n",
    "\n",
    "#Obtain MSEs: \n",
    "lin_error_train = mean_squared_error(linear.predict(X_train), y_train)\n",
    "lin_error_test = mean_squared_error(linear.predict(X_test), y_test)\n",
    "\n",
    "lasso_error_train = mean_squared_error(lasso.predict(X_train), y_train)\n",
    "lasso_error_test = mean_squared_error(lasso.predict(X_test), y_test)\n",
    "\n",
    "ridge_error_train = mean_squared_error(ridge.predict(X_train), y_train)\n",
    "ridge_error_test = mean_squared_error(ridge.predict(X_test), y_test)\n",
    "\n",
    "#Print results\n",
    "print(f'Evaluation of Linear model: \\n MSE train: {lin_error_train:.3} \\n MSE test: {lin_error_test:.3} \\n Intercept: {linear.intercept_:.3} \\n Coefficients: {linear.coef_}\\n')\n",
    "print(f'Evaluation of Lasso model: \\n MSE train: {lasso_error_train:.3} \\n MSE test: {lasso_error_test:.3} \\n Intercept: {lasso.intercept_:.3} \\n Coefficients: {lasso.coef_}\\n')\n",
    "print(f'Evaluation of Ridge model: \\n MSE train: {ridge_error_train:.3} \\n MSE test: {ridge_error_test:.3} \\n Intercept: {ridge.intercept_:.3} \\n Coefficients: {ridge.coef_}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff587",
   "metadata": {},
   "source": [
    "### 2c. Answer a few questions about the models:\n",
    "- Which one best fits the training data?\n",
    "- Which one best fits the test data?\n",
    "- Which one does feature selection by setting most coefficients to zero?- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c91d00",
   "metadata": {},
   "source": [
    "The linear regression model best fits the training data as it has the smallest $MSE_{train}$ result of all the models. Similarly, the model that best fits the test data is the ridge model for having the smallest $MSE_{test}$ result. The lasso model does feature selection as it sets most coefficients to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5167abe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6887218755408672"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "(3/4)*(-(1/3)*math.log2(1/3)-(2/3)*math.log2(2/3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee14c667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112781244591328"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2-(3/4)*math.log2(3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4feb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
